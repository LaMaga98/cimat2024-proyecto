{"cells":[{"cell_type":"markdown","metadata":{},"source":["$$\\textbf{Proyecto de Verano: PLN aplicado a la Bioinformática}$$\n","$$\\textit{Y. Sarahi García Gozález}$$"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:22:19.822802Z","iopub.status.busy":"2024-07-29T19:22:19.822304Z","iopub.status.idle":"2024-07-29T19:22:29.172564Z","shell.execute_reply":"2024-07-29T19:22:29.171749Z","shell.execute_reply.started":"2024-07-29T19:22:19.822742Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import torch\n","import urllib.request\n","import sys\n","# sys.path.append('/kaggle/input/proyecto-archivos/')\n","# import convert_encodings\n","# from convert_encodings import m2\n","from transformers import BertModel, BertConfig, logging\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score\n","#import wandb\n","from datetime import datetime\n","import yaml\n","import os\n","import shutil\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:22:29.174479Z","iopub.status.busy":"2024-07-29T19:22:29.174206Z","iopub.status.idle":"2024-07-29T19:55:30.858519Z","shell.execute_reply":"2024-07-29T19:55:30.857345Z","shell.execute_reply.started":"2024-07-29T19:22:29.174455Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install torchdrug -q"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:30.860361Z","iopub.status.busy":"2024-07-29T19:55:30.860035Z","iopub.status.idle":"2024-07-29T19:55:32.543134Z","shell.execute_reply":"2024-07-29T19:55:32.542144Z","shell.execute_reply.started":"2024-07-29T19:55:30.860332Z"},"trusted":true},"outputs":[],"source":["import torchdrug\n","from torchdrug.datasets import Solubility"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:32.546522Z","iopub.status.busy":"2024-07-29T19:55:32.545876Z","iopub.status.idle":"2024-07-29T19:55:32.552222Z","shell.execute_reply":"2024-07-29T19:55:32.550897Z","shell.execute_reply.started":"2024-07-29T19:55:32.546486Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cpu\n","\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Device: {device}\\n')"]},{"cell_type":"markdown","metadata":{},"source":["Descargar los datos"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:32.554002Z","iopub.status.busy":"2024-07-29T19:55:32.553711Z","iopub.status.idle":"2024-07-29T19:55:32.568685Z","shell.execute_reply":"2024-07-29T19:55:32.567930Z","shell.execute_reply.started":"2024-07-29T19:55:32.553976Z"},"trusted":true},"outputs":[],"source":["class PeptideBERTDataset(torch.utils.data.Dataset):\n","    def __init__(self, input_ids, attention_masks, labels):\n","        self.input_ids = input_ids\n","        self.attention_masks = attention_masks\n","        self.labels = labels\n","\n","        self.length = len(self.input_ids)\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, idx):\n","        input_id = self.input_ids[idx]\n","        attention_mask = self.attention_masks[idx]\n","        label = self.labels[idx]\n","\n","        return {\n","            'input_ids': torch.tensor(input_id, dtype=torch.long),\n","            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n","            'labels': torch.tensor(label, dtype=torch.float)\n","        }"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:32.570077Z","iopub.status.busy":"2024-07-29T19:55:32.569769Z","iopub.status.idle":"2024-07-29T19:55:32.577962Z","shell.execute_reply":"2024-07-29T19:55:32.577163Z","shell.execute_reply.started":"2024-07-29T19:55:32.570039Z"},"trusted":true},"outputs":[],"source":["logging.set_verbosity_error()\n","\n","# Definimos la clase PeptideBERT, que hereda de torch.nn.Module (la clase base para todas las redes neuronales en PyTorch)\n","class PeptideBERT(torch.nn.Module):\n","    def __init__(self, bert_config):\n","        super(PeptideBERT, self).__init__()\n","\n","        # Cargamos el modelo preentrenado\n","        self.protbert = BertModel.from_pretrained(\n","            'Rostlab/prot_bert_bfd', \n","            config=bert_config,\n","            ignore_mismatched_sizes=True\n","        ) \n","        #clasificacion\n","        self.head = torch.nn.Sequential( \n","            torch.nn.Linear(bert_config.hidden_size, 1), #toma la salida de protVert y la convierte en un valor\n","            torch.nn.Sigmoid()\n","        )\n","    # Definimos el método forward que especifica cómo procesar los datos\n","    def forward(self, inputs, attention_mask):\n","        # Pasamos las entradas a través de ProtBert\n","        output = self.protbert(inputs, attention_mask=attention_mask)\n","        # Usamos la salida de ProtBert como entrada a la capa de regresión\n","        return self.head(output.pooler_output)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:32.579328Z","iopub.status.busy":"2024-07-29T19:55:32.579088Z","iopub.status.idle":"2024-07-29T19:55:32.590677Z","shell.execute_reply":"2024-07-29T19:55:32.589982Z","shell.execute_reply.started":"2024-07-29T19:55:32.579307Z"},"trusted":true},"outputs":[],"source":["#criterio de pérdida,optimizador y el planificador de learning rate  para el entrenamiento del modelo\n","\n","def cri_opt_sch(config, model):\n","    #criterio de loss (BinaryCrossEntropy)\n","    criterion = torch.nn.BCELoss()\n","    #optimizador AmadW\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=config['optim']['lr'])\n","    #Scheduler\n","    if config['sch']['name'] == 'onecycle':\n","        ## Durante el entrenamiento, el learning-rate empieza en un valor inicial, aumenta hasta el valor máximo especificado (max_lr), y luego disminuye nuevamente hacia el final del entrenamiento.\n","        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","            optimizer,\n","            max_lr=config['optim']['lr'],\n","            epochs=config['epochs'],\n","            steps_per_epoch=config['sch']['steps']\n","        ) #Ajusta el learning-rate utilizando un ciclo de una sola pasada\n","    elif config['sch']['name'] == 'lronplateau':\n","        ## ajusta el learning-rate basándose en el rendimiento del modelo. Específicamente, reduce la tasa de aprendizaje cuando una métrica de rendimiento ha dejado de mejorar.\n","        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","            optimizer,\n","            mode='max',\n","            factor=config['sch']['factor'],\n","            patience=config['sch']['patience']\n","        )# Reduce lr cuando la métrica especificada ha dejado de mejorar.\n","\n","    return criterion, optimizer, scheduler\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:32.592449Z","iopub.status.busy":"2024-07-29T19:55:32.591877Z","iopub.status.idle":"2024-07-29T19:55:32.603313Z","shell.execute_reply":"2024-07-29T19:55:32.602517Z","shell.execute_reply.started":"2024-07-29T19:55:32.592418Z"},"trusted":true},"outputs":[],"source":["###Función que se encarga del proceso de entrenamiento\n","def train(model, dataloader, optimizer, criterion, scheduler, device):\n","    model.train()  # Pone el modelo en modo de entrenamiento\n","    total_loss = 0.0\n","\n","    for batch in tqdm(dataloader):  # Itera sobre los lotes de datos en el dataloader\n","        inputs = batch['input_ids'].to(device)  # Mueve las entradas al dispositivo (CPU o GPU)\n","        attention_mask = batch['attention_mask'].to(device)  # Mueve la máscara de atención al dispositivo\n","        labels = batch['labels'].to(device)  # Mueve las etiquetas al dispositivo\n","\n","        optimizer.zero_grad()  # Resetea los gradientes del optimizador\n","\n","        logits = model(inputs, attention_mask).squeeze(1)  # Pasa las entradas a través del modelo y ajusta las dimensiones\n","        loss = criterion(logits, labels)  # Calcula la pérdida\n","\n","        loss.backward()  # Calcula los gradientes\n","        optimizer.step()  # Actualiza los parámetros del modelo\n","        # scheduler.step()  # Si el scheduler es OneCycleLR, ajusta la tasa de aprendizaje en cada paso\n","\n","        total_loss += loss.item()  # Acumula la pérdida total\n","\n","    return total_loss / len(dataloader)  # Retorna la pérdida promedio por lote"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:32.604405Z","iopub.status.busy":"2024-07-29T19:55:32.604148Z","iopub.status.idle":"2024-07-29T19:55:32.615658Z","shell.execute_reply":"2024-07-29T19:55:32.614946Z","shell.execute_reply.started":"2024-07-29T19:55:32.604371Z"},"trusted":true},"outputs":[],"source":["def validate(model, dataloader, criterion, device):\n","    model.eval()  # Pone el modelo en modo de evaluación\n","    total_loss = 0.0\n","\n","    ground_truth = []\n","    predictions = []\n","\n","    for batch in tqdm(dataloader):  # Itera sobre los lotes de datos en el dataloader\n","        inputs = batch['input_ids'].to(device)  # Mueve las entradas al dispositivo\n","        attention_mask = batch['attention_mask'].to(device)  # Mueve la máscara de atención al dispositivo\n","        labels = batch['labels'].to(device)  # Mueve las etiquetas al dispositivo\n","\n","        with torch.inference_mode():  # Desactiva el cálculo de gradientes\n","            logits = model(inputs, attention_mask).squeeze(1)  # Pasa las entradas a través del modelo\n","            loss = criterion(logits, labels)  # Calcula la pérdida\n","\n","        total_loss += loss.item()  # Acumula la pérdida total\n","        # Genera predicciones binarias\n","        preds = torch.where(logits > 0.5, 1, 0)  \n","        predictions.extend(preds.cpu().tolist())  # Añade las predicciones a la lista\n","        ground_truth.extend(labels.cpu().tolist())  # Añade las etiquetas reales a la lista\n","\n","    total_loss = total_loss / len(dataloader)  # Calcula la pérdida promedio\n","    accuracy = 100 * accuracy_score(ground_truth, predictions)  # Calcula la precisión\n","\n","    return total_loss, accuracy  # Retorna la pérdida promedio y la precisión"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:32.616998Z","iopub.status.busy":"2024-07-29T19:55:32.616698Z","iopub.status.idle":"2024-07-29T19:55:32.627942Z","shell.execute_reply":"2024-07-29T19:55:32.627220Z","shell.execute_reply.started":"2024-07-29T19:55:32.616975Z"},"trusted":true},"outputs":[],"source":["def test(model, dataloader, device):\n","    model.eval()  # Pone el modelo en modo de evaluación\n","\n","    ground_truth = []\n","    predictions = []\n","\n","    for batch in tqdm(dataloader):  # Itera sobre los lotes de datos en el dataloader\n","        inputs = batch['input_ids'].to(device)  # Mueve las entradas al dispositivo\n","        attention_mask = batch['attention_mask'].to(device)  # Mueve la máscara de atención al dispositivo\n","        labels = batch['labels']  # Las etiquetas permanecen en la CPU\n","\n","        with torch.inference_mode():  # Desactiva el cálculo de gradientes\n","            logits = model(inputs, attention_mask).squeeze(1)  # Pasa las entradas a través del modelo\n","\n","        preds = torch.where(logits > 0.5, 1, 0)  # Genera predicciones binarias\n","        predictions.extend(preds.cpu().tolist())  # Añade las predicciones a la lista\n","        ground_truth.extend(labels.tolist())  # Añade las etiquetas reales a la lista\n","\n","    accuracy = 100 * accuracy_score(ground_truth, predictions)  # Calcula la precisión\n","\n","    return accuracy  # Retorna la precisión\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:32.631853Z","iopub.status.busy":"2024-07-29T19:55:32.631466Z","iopub.status.idle":"2024-07-29T19:55:32.641770Z","shell.execute_reply":"2024-07-29T19:55:32.640955Z","shell.execute_reply.started":"2024-07-29T19:55:32.631828Z"},"trusted":true},"outputs":[],"source":["def train_model(model):\n","    print(f'{\"=\"*30}{\"TRAINING\":^20}{\"=\"*30}')\n","\n","    best_acc = 0 #inicializa la mejor precisión en cero\n","\n","    #iteramos cada época\n","    for epoch in range(config['epochs']):\n","\n","        #llamamos a la funcion de entrenamiento\n","        train_loss = train(model, train_data_loader, optimizer, criterion, scheduler, device)\n","        #obtenemos learning rate\n","        curr_lr = optimizer.param_groups[0]['lr']\n","        #imprimimos loss de entrenamiento y learning rate\n","        print(f'Epoch {epoch+1}/{config[\"epochs\"]} - Train Loss: {train_loss}\\tLR: {curr_lr}')\n","        #imprimimos loss y accuracy de validacion\n","        val_loss, val_acc = validate(model, val_data_loader, criterion, device)\n","        print(f'Epoch {epoch+1}/{config[\"epochs\"]} - Validation Loss: {val_loss}\\tValidation Accuracy: {val_acc}\\n')\n","        #Actualizar el Scheduler:\n","        scheduler.step(val_acc)\n","\n","        #Registrar Métricas con wandb\n","        if not config['debug']:\n","            wandb.log({\n","                'train_loss': train_loss, \n","                'val_loss': val_loss, \n","                'val_accuracy': val_acc, \n","                'lr': curr_lr\n","            })\n","        #Guardamos mejor modelo\n","        if val_acc >= best_acc and not config['debug']:\n","            best_acc = val_acc\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'scheduler_state_dict': scheduler.state_dict(),\n","                'train_loss': train_loss,\n","                'val_loss': val_loss,\n","                'acc': val_acc, \n","                'lr': curr_lr\n","            }, f'{save_dir}/model.pt')\n","            print('Model Saved\\n')\n","    wandb.finish()\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Solubilidad"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:32.643100Z","iopub.status.busy":"2024-07-29T19:55:32.642825Z","iopub.status.idle":"2024-07-29T19:55:33.838226Z","shell.execute_reply":"2024-07-29T19:55:33.837204Z","shell.execute_reply.started":"2024-07-29T19:55:32.643070Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["19:55:32   Extracting f'/kaggle/working/solubility.tar.gz to f'/kaggle/working\n"]},{"name":"stderr","output_type":"stream","text":["Constructing proteins from sequences: 100%|██████████| 71419/71419 [00:00<00:00, 118807.44it/s]\n"]}],"source":["ds=Solubility(\"f'/kaggle/working/\",lazy=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:33.839991Z","iopub.status.busy":"2024-07-29T19:55:33.839619Z","iopub.status.idle":"2024-07-29T19:55:33.844748Z","shell.execute_reply":"2024-07-29T19:55:33.843742Z","shell.execute_reply.started":"2024-07-29T19:55:33.839961Z"},"trusted":true},"outputs":[],"source":["sequences=ds.sequences\n","targets=ds.targets['solubility']"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:33.846229Z","iopub.status.busy":"2024-07-29T19:55:33.845927Z","iopub.status.idle":"2024-07-29T19:55:35.679645Z","shell.execute_reply":"2024-07-29T19:55:35.678930Z","shell.execute_reply.started":"2024-07-29T19:55:33.846203Z"},"trusted":true},"outputs":[],"source":["aminoacidos = ['G', 'A', 'S', 'P', 'V', 'T', 'C', 'I', 'L', 'N', 'D', 'Q', 'K', 'E', 'M', 'H', 'F', 'R', 'Y', 'W']\n","#diccionario de mapeo\n","letter_to_number = {letter: index  for index, letter in enumerate(aminoacidos)}\n","# Función para convertir secuencias de letras a secuencias de números\n","def convert_sequences_to_numbers(sequences, mapping):\n","    return [[mapping[letter] for letter in seq] for seq in sequences]\n","\n","sequences_number=convert_sequences_to_numbers(sequences, letter_to_number)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:35.681148Z","iopub.status.busy":"2024-07-29T19:55:35.680801Z","iopub.status.idle":"2024-07-29T19:55:35.698697Z","shell.execute_reply":"2024-07-29T19:55:35.697825Z","shell.execute_reply.started":"2024-07-29T19:55:35.681113Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["La longitud del string más largo es: 1200\n"]}],"source":["#longitud del string más larga\n","max_length = max(len(s) for s in sequences)\n","\n","print(\"La longitud del string más largo es:\", max_length)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:35.700008Z","iopub.status.busy":"2024-07-29T19:55:35.699726Z","iopub.status.idle":"2024-07-29T19:55:35.710989Z","shell.execute_reply":"2024-07-29T19:55:35.710191Z","shell.execute_reply.started":"2024-07-29T19:55:35.699985Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[62478, 6942, 1999]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["ds.num_samples #train,valid,test"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:35.712698Z","iopub.status.busy":"2024-07-29T19:55:35.712422Z","iopub.status.idle":"2024-07-29T19:55:45.443178Z","shell.execute_reply":"2024-07-29T19:55:45.442234Z","shell.execute_reply.started":"2024-07-29T19:55:35.712667Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-29 19:55:37.383398: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-29 19:55:37.383500: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-29 19:55:37.509124: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from torch.utils.data import DataLoader\n","import numpy as np\n","from keras.preprocessing.sequence import pad_sequences\n","\n","def atention_mask(array_sequences, max_length):\n","    m = len(array_sequences)\n","    atention_mask_sequence = np.zeros((m, max_length), dtype=np.float64)\n","\n","    for i, seq in enumerate(array_sequences):\n","        seq_len = min(len(seq), max_length)\n","        atention_mask_sequence[i, :seq_len] = 1\n","\n","    return atention_mask_sequence\n","\n","\n","def load_data_torchdrug(sequences, targets, ds, max_length,truncate=True):\n","    print(f'{\"=\"*30}{\"DATA\":^20}{\"=\"*30}')\n","    \n","    n0=ds.num_samples[0] #lista que contiene el número de muestras por set:train,val,test\n","    n1=ds.num_samples[0]+ds.num_samples[1]\n","   \n","    \n","    train_sequences=[seq for seq in sequences[0:n0] if len(seq)<500]\n","    train_targets=np.array([target for seq,target in zip(sequences[0:n0],targets[0:n0]) if len(seq)<500])\n","  \n","    val_sequences=[seq for seq in sequences[n0:n1] if len(seq)<500]\n","    val_targets=np.array([target for seq,target in zip(sequences[n0:n1],targets[n0:n1]) if len(seq)<500])\n","\n","    test_sequences=[seq for seq in sequences[n1:] if len(seq)<500]\n","    test_targets=np.array([target for seq,target in zip(sequences[n1:],targets[n1:]) if len(seq)<500])\n","\n","    #cnvertir a array\n","    # Padear las secuencias para que todas tengan la misma longitud\n","    max_len = 500\n","    train_sequences = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n","    val_sequences= pad_sequences(val_sequences, maxlen=max_len, padding='post')\n","    test_sequences = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n","    \n","    \n","    # Crear las máscaras de atención\n","    attention_mask_train = (train_sequences > 0).astype(np.float64)\n","    attention_mask_val = (val_sequences > 0).astype(np.float64)\n","    attention_mask_test = (test_sequences > 0).astype(np.float64)\n","    \n","    \n","    \n","    train_dataset = PeptideBERTDataset(input_ids=train_sequences, attention_masks=attention_mask_train, labels=train_targets)\n","    val_dataset = PeptideBERTDataset(input_ids=val_sequences, attention_masks=attention_mask_val, labels=val_targets)\n","    test_dataset = PeptideBERTDataset(input_ids=test_sequences, attention_masks=attention_mask_test, labels=test_targets)\n","\n","    train_data_loader = DataLoader(\n","        train_dataset,\n","        batch_size=16,\n","        shuffle=True\n","    )\n","\n","    val_data_loader = DataLoader(\n","        val_dataset,\n","        batch_size=16,\n","        shuffle=False\n","    )\n","\n","    test_data_loader = DataLoader(\n","        test_dataset,\n","        batch_size=16,\n","        shuffle=False\n","    )\n","\n","    print('Batch size: ', 8)\n","\n","    print('Train dataset samples: ', len(train_dataset))\n","    print('Validation dataset samples: ', len(val_dataset))\n","    print('Test dataset samples: ', len(test_dataset))\n","\n","    print('Train dataset batches: ', len(train_data_loader))\n","    print('Validation dataset batches: ', len(val_data_loader))\n","    print('Test dataset batches: ', len(test_data_loader))\n","\n","    print()\n","\n","    return train_data_loader, val_data_loader, test_data_loader"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:45.444702Z","iopub.status.busy":"2024-07-29T19:55:45.444396Z","iopub.status.idle":"2024-07-29T19:55:46.943601Z","shell.execute_reply":"2024-07-29T19:55:46.942624Z","shell.execute_reply.started":"2024-07-29T19:55:45.444677Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["==============================        DATA        ==============================\n","Batch size:  8\n","Train dataset samples:  56845\n","Validation dataset samples:  6308\n","Test dataset samples:  1774\n","Train dataset batches:  3553\n","Validation dataset batches:  395\n","Test dataset batches:  111\n","\n"]}],"source":["train_data_loader, val_data_loader, test_data_loader = load_data_torchdrug(sequences_number,targets,ds,max_length)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:46.945235Z","iopub.status.busy":"2024-07-29T19:55:46.944887Z","iopub.status.idle":"2024-07-29T19:55:46.987278Z","shell.execute_reply":"2024-07-29T19:55:46.986457Z","shell.execute_reply.started":"2024-07-29T19:55:46.945210Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([ 0, 14,  7,  8, 12,  5,  9,  8, 16,  0, 15,  5, 18, 11, 16, 12,  2,  7,\n","          5, 10,  4,  8,  1, 12,  1,  9, 13, 13, 12,  2,  0, 10, 17,  8,  1,  0,\n","          4,  1,  1, 13,  2,  1, 13, 13, 17,  4,  1,  1, 12,  4,  4,  8,  2, 12,\n","         14,  5,  8,  0, 10,  8, 17,  9,  9,  3,  4,  4,  3, 18, 13,  5, 10, 13,\n","          4,  5, 17,  7,  7, 11, 10, 11,  4,  9, 10, 17,  7, 15, 10,  2,  7, 12,\n","          9, 19,  5,  4, 13, 13,  8, 17, 13, 19,  7,  8, 10, 15, 12,  5,  5, 10,\n","          1, 10,  7, 12, 17,  4,  1, 17,  0,  8,  5,  2, 13,  7,  7,  1,  1,  4,\n","          5, 12,  8, 14,  2,  9,  8, 10,  8,  7, 18,  0,  1, 12, 12,  7, 17,  4,\n","          7,  1, 15,  1,  9,  5,  5,  7,  0,  8,  3,  0,  5, 16,  2,  1, 17,  8,\n","         11,  3,  9, 15,  3,  5, 10, 10,  3, 10,  0,  7,  8,  1,  2,  8, 14, 13,\n","          0,  8,  5, 18,  0,  7,  0, 10,  1,  4,  7,  0,  8,  9,  3,  4, 10, 10,\n","          2,  5, 10,  2,  4,  4, 17,  8,  8,  9, 12, 16, 13, 13, 16, 17,  2, 12,\n","         19, 10,  4,  3,  5, 11,  5,  6,  4,  8,  1, 15,  4, 12,  5, 11, 14, 13,\n","          1, 14, 17, 17,  0,  1,  3,  5,  0,  8,  4, 16, 11,  2,  7,  1,  0,  2,\n","         13, 12,  0,  9,  5,  1, 16,  0, 16, 10,  0,  1,  5,  7, 13, 13,  1, 17,\n","         11,  8,  1,  8, 11,  2,  0,  1,  1,  5,  0,  3,  9,  4, 14, 18, 16, 13,\n","          5,  0, 11,  0,  2, 13,  8,  2,  2, 10,  1, 15, 16,  0,  4, 10, 11,  4,\n","          5, 14, 13,  1, 17,  6, 18,  0, 16,  1, 12, 12, 16, 10,  3, 16,  8,  4,\n","          9,  5,  4,  4,  0, 16,  7,  0,  3, 13, 18,  8, 18, 10,  2, 12, 11,  4,\n","          7, 17,  1,  0,  8, 13, 10, 15, 16, 14,  0, 12,  8,  5,  0,  7,  2, 14,\n","          0,  6, 10,  4,  6, 18,  5,  9, 15, 14, 12,  1, 10, 11,  9, 10,  4, 13,\n","          9,  8,  2,  4,  8,  8,  5,  1,  1,  0,  6,  9, 16,  7, 14,  0,  7,  3,\n","         15,  0, 10, 10,  4, 14,  8,  9, 18, 11,  5,  5,  0, 18, 15, 13,  5,  1,\n","          5,  8, 17, 13,  8, 16,  0,  8, 12,  3,  7, 12, 13, 16, 10, 11, 19, 14,\n","         13, 12, 14,  0, 16,  2, 13,  9,  0, 12,  8,  5,  2, 17,  1,  0, 10,  1,\n","          2,  7, 16,  8, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n"," 'attention_mask': tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n","         1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n","         1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n","         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'labels': tensor(1.)}"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["train_data_loader.dataset[0]"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:46.988547Z","iopub.status.busy":"2024-07-29T19:55:46.988285Z","iopub.status.idle":"2024-07-29T19:55:46.998450Z","shell.execute_reply":"2024-07-29T19:55:46.997563Z","shell.execute_reply.started":"2024-07-29T19:55:46.988524Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([ 0, 14,  7,  8, 12,  5,  9,  8, 16,  0, 15,  5, 18, 11, 16, 12,  2,  7,\n","         5, 10,  4,  8,  1, 12,  1,  9, 13, 13, 12,  2,  0, 10, 17,  8,  1,  0,\n","         4,  1,  1, 13,  2,  1, 13, 13, 17,  4,  1,  1, 12,  4,  4,  8,  2, 12,\n","        14,  5,  8,  0, 10,  8, 17,  9,  9,  3,  4,  4,  3, 18, 13,  5, 10, 13,\n","         4,  5, 17,  7,  7, 11, 10, 11,  4,  9, 10, 17,  7, 15, 10,  2,  7, 12,\n","         9, 19,  5,  4, 13, 13,  8, 17, 13, 19,  7,  8, 10, 15, 12,  5,  5, 10,\n","         1, 10,  7, 12, 17,  4,  1, 17,  0,  8,  5,  2, 13,  7,  7,  1,  1,  4,\n","         5, 12,  8, 14,  2,  9,  8, 10,  8,  7, 18,  0,  1, 12, 12,  7, 17,  4,\n","         7,  1, 15,  1,  9,  5,  5,  7,  0,  8,  3,  0,  5, 16,  2,  1, 17,  8,\n","        11,  3,  9, 15,  3,  5, 10, 10,  3, 10,  0,  7,  8,  1,  2,  8, 14, 13,\n","         0,  8,  5, 18,  0,  7,  0, 10,  1,  4,  7,  0,  8,  9,  3,  4, 10, 10,\n","         2,  5, 10,  2,  4,  4, 17,  8,  8,  9, 12, 16, 13, 13, 16, 17,  2, 12,\n","        19, 10,  4,  3,  5, 11,  5,  6,  4,  8,  1, 15,  4, 12,  5, 11, 14, 13,\n","         1, 14, 17, 17,  0,  1,  3,  5,  0,  8,  4, 16, 11,  2,  7,  1,  0,  2,\n","        13, 12,  0,  9,  5,  1, 16,  0, 16, 10,  0,  1,  5,  7, 13, 13,  1, 17,\n","        11,  8,  1,  8, 11,  2,  0,  1,  1,  5,  0,  3,  9,  4, 14, 18, 16, 13,\n","         5,  0, 11,  0,  2, 13,  8,  2,  2, 10,  1, 15, 16,  0,  4, 10, 11,  4,\n","         5, 14, 13,  1, 17,  6, 18,  0, 16,  1, 12, 12, 16, 10,  3, 16,  8,  4,\n","         9,  5,  4,  4,  0, 16,  7,  0,  3, 13, 18,  8, 18, 10,  2, 12, 11,  4,\n","         7, 17,  1,  0,  8, 13, 10, 15, 16, 14,  0, 12,  8,  5,  0,  7,  2, 14,\n","         0,  6, 10,  4,  6, 18,  5,  9, 15, 14, 12,  1, 10, 11,  9, 10,  4, 13,\n","         9,  8,  2,  4,  8,  8,  5,  1,  1,  0,  6,  9, 16,  7, 14,  0,  7,  3,\n","        15,  0, 10, 10,  4, 14,  8,  9, 18, 11,  5,  5,  0, 18, 15, 13,  5,  1,\n","         5,  8, 17, 13,  8, 16,  0,  8, 12,  3,  7, 12, 13, 16, 10, 11, 19, 14,\n","        13, 12, 14,  0, 16,  2, 13,  9,  0, 12,  8,  5,  2, 17,  1,  0, 10,  1,\n","         2,  7, 16,  8, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["train_data_loader.dataset[0]['input_ids']"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T19:55:46.999685Z","iopub.status.busy":"2024-07-29T19:55:46.999449Z","iopub.status.idle":"2024-07-29T19:55:47.005617Z","shell.execute_reply":"2024-07-29T19:55:47.004829Z","shell.execute_reply.started":"2024-07-29T19:55:46.999664Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([500])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["train_data_loader.dataset[7410]['input_ids'].size()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T21:20:50.457866Z","iopub.status.busy":"2024-07-29T21:20:50.457476Z","iopub.status.idle":"2024-07-29T21:20:50.469526Z","shell.execute_reply":"2024-07-29T21:20:50.468717Z","shell.execute_reply.started":"2024-07-29T21:20:50.457835Z"},"trusted":true},"outputs":[],"source":["##Configuración y Preparación###\n","#llamamos al archivo donde se guarda la config del modelo peptidebert\n","config = yaml.load(open('/kaggle/input/proyecto-archivos/config.yaml', 'r'), Loader=yaml.FullLoader)\n","config['task'] = 'fluor'\n","config['batch_size'] = 16\n","config['epochs'] = 8\n","config['optim']['lr'] = 1.0e-5\n","config['sch']['steps'] = len(train_data_loader)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T21:20:53.612826Z","iopub.status.busy":"2024-07-29T21:20:53.611934Z","iopub.status.idle":"2024-07-29T21:20:53.619907Z","shell.execute_reply":"2024-07-29T21:20:53.618683Z","shell.execute_reply.started":"2024-07-29T21:20:53.612762Z"},"trusted":true},"outputs":[],"source":["def create_model_torchdrug(config):\n","    bert_config = BertConfig(\n","        vocab_size=25,\n","        hidden_size=480,\n","        num_hidden_layers=12,\n","        num_attention_heads=12,\n","        hidden_dropout_prob=0.15,\n","        max_position_embeddings= 512 #maximo len de preentrenamiento HF\n","    )\n","    #creamos una istancia de PeptideBERT utilizando la configuración de BERT definida\n","    model = PeptideBERT(bert_config).to(device)\n","    #regresamos el modelo\n","    return model"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T21:20:56.959298Z","iopub.status.busy":"2024-07-29T21:20:56.958936Z","iopub.status.idle":"2024-07-29T21:21:20.705127Z","shell.execute_reply":"2024-07-29T21:21:20.703987Z","shell.execute_reply.started":"2024-07-29T21:20:56.959268Z"},"trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:5ran947k) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>▁▁</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>val_accuracy</td><td>▁▁</td></tr><tr><td>val_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.0001</td></tr><tr><td>train_loss</td><td>0.68198</td></tr><tr><td>val_accuracy</td><td>58.33862</td></tr><tr><td>val_loss</td><td>0.67963</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">sol-0729_2004</strong> at: <a href='https://wandb.ai/sara-garcia/PeptideBERT/runs/5ran947k' target=\"_blank\">https://wandb.ai/sara-garcia/PeptideBERT/runs/5ran947k</a><br/> View project at: <a href='https://wandb.ai/sara-garcia/PeptideBERT' target=\"_blank\">https://wandb.ai/sara-garcia/PeptideBERT</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240729_200556-5ran947k/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:5ran947k). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.17.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240729_212058-8b4ka2d1</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/sara-garcia/PeptideBERT/runs/8b4ka2d1' target=\"_blank\">sol-0729_2120</a></strong> to <a href='https://wandb.ai/sara-garcia/PeptideBERT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/sara-garcia/PeptideBERT' target=\"_blank\">https://wandb.ai/sara-garcia/PeptideBERT</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/sara-garcia/PeptideBERT/runs/8b4ka2d1' target=\"_blank\">https://wandb.ai/sara-garcia/PeptideBERT/runs/8b4ka2d1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["\n","#creamos el modelo\n","model_torchdrug = create_model_torchdrug(config)\n","\n","#configuramos criterio de pérdida, optimizador y scheduler\n","criterion, optimizer, scheduler = cri_opt_sch(config, model_torchdrug)\n","\n","\n","#Configuración de Weights & Biases (WandB)\n","if not config['debug']:\n","    run_name = f'{config[\"task\"]}-{datetime.now().strftime(\"%m%d_%H%M\")}'\n","    wandb.init(project='PeptideBERT', name=run_name)\n","\n","    save_dir = f'/kaggle/working/checkpoints/{run_name}'\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","    else:\n","        print('ya existe')\n","    shutil.copy('/kaggle/input/proyecto-archivos/config.yaml', f'{save_dir}/config.yaml')\n","    shutil.copy('/kaggle/input/model-peptidos/network.py', f'{save_dir}/network.py')"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-07-29T21:21:35.562471Z","iopub.status.busy":"2024-07-29T21:21:35.561550Z","iopub.status.idle":"2024-07-30T01:46:12.797657Z","shell.execute_reply":"2024-07-30T01:46:12.796855Z","shell.execute_reply.started":"2024-07-29T21:21:35.562438Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["==============================      TRAINING      ==============================\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3553/3553 [31:51<00:00,  1.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/8 - Train Loss: 0.6342966494226737\tLR: 1e-05\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 395/395 [01:12<00:00,  5.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/8 - Validation Loss: 0.5753310979921606\tValidation Accuracy: 65.91629676601141\n","\n","Model Saved\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3553/3553 [31:51<00:00,  1.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/8 - Train Loss: 0.5640089373051064\tLR: 1e-05\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 395/395 [01:12<00:00,  5.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/8 - Validation Loss: 0.5345281376114375\tValidation Accuracy: 70.62460367786937\n","\n","Model Saved\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3553/3553 [31:50<00:00,  1.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/8 - Train Loss: 0.5432118680438223\tLR: 1e-05\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 395/395 [01:12<00:00,  5.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/8 - Validation Loss: 0.5378148098535176\tValidation Accuracy: 69.57831325301204\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3553/3553 [31:50<00:00,  1.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/8 - Train Loss: 0.5347400006444697\tLR: 1e-05\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 395/395 [01:12<00:00,  5.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/8 - Validation Loss: 0.5305518093742901\tValidation Accuracy: 71.06848446417247\n","\n","Model Saved\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3553/3553 [31:50<00:00,  1.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/8 - Train Loss: 0.5297306505703705\tLR: 1e-05\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 395/395 [01:12<00:00,  5.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/8 - Validation Loss: 0.5223847663100761\tValidation Accuracy: 71.16360177552315\n","\n","Model Saved\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3553/3553 [31:50<00:00,  1.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/8 - Train Loss: 0.524560482635184\tLR: 1e-05\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 395/395 [01:12<00:00,  5.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/8 - Validation Loss: 0.5186560472355614\tValidation Accuracy: 71.8294229549778\n","\n","Model Saved\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3553/3553 [31:50<00:00,  1.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/8 - Train Loss: 0.5208642824523858\tLR: 1e-05\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 395/395 [01:12<00:00,  5.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/8 - Validation Loss: 0.5182853369773188\tValidation Accuracy: 72.28915662650603\n","\n","Model Saved\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3553/3553 [31:49<00:00,  1.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8/8 - Train Loss: 0.5171788369991932\tLR: 1e-05\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 395/395 [01:12<00:00,  5.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8/8 - Validation Loss: 0.5202548097960557\tValidation Accuracy: 71.70259987317692\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▅▇▇▇█▇</td></tr><tr><td>val_loss</td><td>█▃▃▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>1e-05</td></tr><tr><td>train_loss</td><td>0.51718</td></tr><tr><td>val_accuracy</td><td>71.7026</td></tr><tr><td>val_loss</td><td>0.52025</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">sol-0729_2120</strong> at: <a href='https://wandb.ai/sara-garcia/PeptideBERT/runs/8b4ka2d1' target=\"_blank\">https://wandb.ai/sara-garcia/PeptideBERT/runs/8b4ka2d1</a><br/> View project at: <a href='https://wandb.ai/sara-garcia/PeptideBERT' target=\"_blank\">https://wandb.ai/sara-garcia/PeptideBERT</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240729_212058-8b4ka2d1/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["#Entrenamiento del Modelo\n","train_model(model_torchdrug)\n","if not config['debug']:\n","    model_torchdrug.load_state_dict(torch.load(f'{save_dir}/model.pt')['model_state_dict'], strict=False)\n"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T01:49:39.432673Z","iopub.status.busy":"2024-07-30T01:49:39.432012Z","iopub.status.idle":"2024-07-30T01:49:59.705037Z","shell.execute_reply":"2024-07-30T01:49:59.704144Z","shell.execute_reply.started":"2024-07-30T01:49:39.432640Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 111/111 [00:20<00:00,  5.48it/s]"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 67.98196166854565%\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["#test\n","test_acc = test(model_torchdrug, test_data_loader, device)\n","print(f'Test Accuracy: {test_acc}%')"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T02:02:36.325700Z","iopub.status.busy":"2024-07-30T02:02:36.325072Z","iopub.status.idle":"2024-07-30T02:02:58.185584Z","shell.execute_reply":"2024-07-30T02:02:58.184603Z","shell.execute_reply.started":"2024-07-30T02:02:36.325670Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 67.98%\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","         0.0       0.63      0.86      0.73       879\n","         1.0       0.79      0.50      0.61       895\n","\n","    accuracy                           0.68      1774\n","   macro avg       0.71      0.68      0.67      1774\n","weighted avg       0.71      0.68      0.67      1774\n","\n"]}],"source":["# Función para cargar el modelo guardado\n","def load_trained_model(save_path, config):\n","    model = create_model_torchdrug(config)\n","    checkpoint = torch.load(save_path, map_location=device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    return model\n","\n","# Función para realizar la inferencia\n","def infer(model, dataloader, device):\n","    model.eval()  # Pone el modelo en modo de evaluación\n","    predictions = []\n","    ground_truth = []\n","\n","    with torch.no_grad():  # Desactiva el cálculo de gradientes\n","        for batch in dataloader:\n","            inputs = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            logits = model(inputs, attention_mask).squeeze(1)\n","            preds = torch.where(logits > 0.5, 1, 0)\n","            predictions.extend(preds.cpu().tolist())\n","            ground_truth.extend(labels.cpu().tolist())\n","\n","    return predictions, ground_truth\n","\n","\n","save_path = f'{save_dir}/model.pt'  # Ruta del modelo guardado\n","\n","# Cargar el modelo entrenado\n","model = load_trained_model(save_path, config)\n","\n","\n","\n","# Realizar inferencia en los datos de prueba\n","predictions, ground_truth = infer(model, test_data_loader, device)\n","\n","# Imprimir resultados\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","accuracy = accuracy_score(ground_truth, predictions)\n","report = classification_report(ground_truth, predictions)\n","\n","print(f'Test Accuracy: {accuracy * 100:.2f}%')\n","print('Classification Report:')\n","print(report)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5111414,"sourceId":8553322,"sourceType":"datasetVersion"},{"datasetId":5111521,"sourceId":8553483,"sourceType":"datasetVersion"},{"datasetId":5111468,"sourceId":8553979,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":4}
